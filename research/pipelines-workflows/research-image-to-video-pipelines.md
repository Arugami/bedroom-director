# AI Creators: Workflows, Pain Points, and Emerging Needs

AI-driven content creators span from individual concept artists and social-media designers to marketing teams, game studios, and filmmakers. Broadly, research distinguishes **inspiration-oriented** creators (seeking concept images and ideas) from **deliverable-oriented** creators (aiming for polished final assets)[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=Users%E2%80%99%20goals%20were%20either%20inspiration,oriented)[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=%23%20Deliverable). For example, one artist might use AI to brainstorm logo concepts or mood boards, while another uses it to generate final posters or storyboards for a client. Similarly, game developers or VFX studios traditionally employ whole art teams for asset pipelines, whereas now a solo developer might leverage AI to rapidly prototype characters or scenes[layer.ai](https://www.layer.ai/blog/how-bring-artist-first-ai-studio-workflows#:~:text=The%20pipeline%20consists%20of%20steps,allowing%20gamedevs%20to%20create%20faster). In enterprise settings, marketers and agencies (who “use AI for everything from logo generation to scaled brand creative”[superside.com](https://www.superside.com/blog/ai-video-generators#:~:text=There%E2%80%99s%20no%20question%20that%20AI,generation%20%20to%20%2053)) form another archetype, focusing on brand consistency and rapid output. Across archetypes, common constraints include tight deadlines, budget limits, strict style guidelines, and the technical proficiency required to operate multiple AI tools.

## Workflow Mapping

AI-based image→video production generally follows a multi-stage pipeline:

* **Ideation & Pre-production:** Creators define goals and gather inspiration. They often use LLMs (ChatGPT, Gemini, Claude) to brainstorm scenarios, generate shot ideas or refine concepts[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=This%20step%20felt%20overwhelming%20to,chatbots%2C%20or%20external%20resources)[vp-land.com](https://www.vp-land.com/p/step-by-step-the-state-of-ai-filmmaking-workflows#:~:text=Every%20film%20begins%20with%20a,detailed%20prompts%20for%20image%20generation). For instance, a filmmaker might ask ChatGPT for scene descriptions (e.g. “chased through a mine tunnel on a cart”), or designers might browse AI-generated galleries (like MidLibrary or Dribbble) for style references[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=Participants%20also%20used%20genAI%20chatbots,pasted%20these%20prompts%20into%20Midjourney)[vp-land.com](https://www.vp-land.com/p/step-by-step-the-state-of-ai-filmmaking-workflows#:~:text=Establishing%20a%20Consistent%20Visual%20Style). This “Define” phase alleviates the blank-page problem by producing starter prompts or visual mood boards.

* **Prompt Writing & Exploration:** Next, creators craft text prompts and generate many candidate images. They typically iterate exhaustively – NNG observers saw 20–80 images per concept[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=Creating%20Quantity). Two common strategies are used: **prompt repetition** (resubmitting the same prompt to harvest the algorithm’s randomness) and **prompt variation** (tweaking wording to explore directions)[nngroup.comnngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=). For example, an artist might suffix Midjourney commands (e.g. `--r 10`) to produce batches of variations[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=Expert%20users%20in%20our%20study,based%20on%20the%20same%20prompt), or write three related prompts to capture different compositions. Expert users rely on prompt libraries or Midjourney’s `/describe` tool to generate options, but regular users find “coming up with numerous prompt alternatives rapidly… cognitively challenging”[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=This%20prompting%20strategy%20came%20with,cognitively%20challenging%20for%20regular%20users). The goal of this “Explore” stage is to produce at least one image that roughly matches the vision.

* **Refinement & Editing:** Once a base image is selected, creators enter refinement. They may use inpainting (image-editing within the AI model) or blend multiple outputs. However, current generative tools offer limited fine control, so artists often juggle external editors. As one user put it, “Midjourney is a generator, not an editor”[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=Lack%20of%20User%20Control%3A%20Fighting,the%20AI). Small edits (e.g. changing a sofa’s pattern) can cause large unpredictable shifts, forcing repeated trials[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=One%20study%20participant%20wanted%20to,randomness%20of%20the%20AI%20tool). To overcome this, creators frequently export AI outputs to tools like Photoshop or Painter for manual fixes[nngroup.com](https://www.nngroup.com/articles/ai-imagegen-stages/#:~:text=Another%20example%20occurred%20when%20a,tool%20like%20Photoshop%20for%20editing)). This “Refine” stage is where technical complexity spikes, and creators battle both model randomness and interface limitations.

* **Image → Video & Beyond:** (Content continues as in source document…)

