# AI Curator Pipeline (Data Folder)

This folder stores inputs/outputs for the **AI model & tool curator** described in
`docs/strategy/ai-model-strategy-and-training-roadmap.md` (section 12).

## Files

- `curated_candidates.jsonl`  
  NDJSON file where each line is a JSON object representing a *single* candidate
  tool/model that has already been processed by an external AI curator service.

  The expected schema matches the doc:

  ```jsonc
  {
    "candidate_id": "openrouter:google_nano-banana-pro",
    "raw_source": { /* original API payload + metadata */ },
    "normalized": { /* mapped to our schema */ },
    "dedupe": {
      "status": "distinct",          // or "duplicate", "platform_wrapper"
      "duplicate_of": null,
      "similarity_score": 0.21
    },
    "fit": {
      "fit_score": 0.93,
      "recommended_bd_category": "IMAGE_GEN",
      "reason": "Why this fits Bedroom Directorâ€¦"
    },
    "decision": {
      "action": "accept",            // "accept", "experimental", "reject"
      "reason": "High fit score and distinct."
    }
  }
  ```

## How to Apply Curated Results

Once `curated_candidates.jsonl` is generated by an AI service:

1. From the repo root, run:

   ```bash
   python scripts/updates/apply_ai_curator_results.py
   ```

2. The script will:
   - Create a timestamped backup under `data/backups/`.
   - Merge accepted / experimental tools into `data/ai_video_image_models.csv`.
   - Rebuild `data/models.json` via `scripts/utilities/sync_to_json.py`.

3. Check `data/models.json` or the Tool Catalog UI to verify that new tools
   appear as expected.

This keeps the data pipeline simple: the **AI curator generates the JSON;**
our scripts handle CSV/JSON synchronization and avoid manual spreadsheet edits.

